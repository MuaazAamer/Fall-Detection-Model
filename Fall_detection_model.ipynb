{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install skl2onnx\n",
        "! pip install kagglehub\n",
        "! pip install onnxmltools\n",
        "! pip install onnxruntime\n",
        "! pip install tensorflow\n",
        "!pip install onnx-tf"
      ],
      "metadata": {
        "id": "sb7KOhUXZpT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GET DATASET FROM KAGGLE**"
      ],
      "metadata": {
        "id": "5Urr0oCes2IH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"kmknation/mobifall-dataset-v20\")"
      ],
      "metadata": {
        "id": "zexeHMPJfTKy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROCESS RAW DATA**"
      ],
      "metadata": {
        "id": "DVzCVgq0tC6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import kagglehub\n",
        "from scipy.stats import skew, kurtosis  # For skewness and kurtosis\n",
        "\n",
        "# Updated FFT Function (no longer needed for dominant frequency)\n",
        "def compute_fft(signal, sampling_rate):\n",
        "    \"\"\"Compute the FFT and return all frequencies (positive and negative) and magnitudes.\"\"\"\n",
        "    N = len(signal)\n",
        "    freqs = np.fft.fftfreq(N, d=1 / sampling_rate)\n",
        "    magnitudes = np.abs(np.fft.fft(signal)) / N\n",
        "    return np.fft.fftshift(freqs), np.fft.fftshift(magnitudes)\n",
        "\n",
        "def summarize_file(base_address, file_name, window_size_in_secs=4, stride_fraction=0.1):\n",
        "    # Initialize arrays\n",
        "    x, y, z, time_stamp = [], [], [], []\n",
        "\n",
        "    # Read data\n",
        "    with open(os.path.join(base_address, file_name), 'r') as file:\n",
        "        for _ in range(16):  # Skip header\n",
        "            next(file)\n",
        "        for line in file:\n",
        "            values = line.strip().split(',')\n",
        "            if len(values) >= 4:\n",
        "                time_stamp.append(float(values[0].strip()))\n",
        "                x.append(float(values[1].strip()))\n",
        "                y.append(float(values[2].strip()))\n",
        "                z.append(float(values[3].strip()))\n",
        "\n",
        "    # Convert times to nanoseconds for calculations\n",
        "    window_size_ns = window_size_in_secs * 1e9\n",
        "    stride_ns = int(stride_fraction * window_size_ns)\n",
        "\n",
        "    # Sliding window\n",
        "    results = []\n",
        "    start_idx = 0\n",
        "    while start_idx < len(time_stamp):\n",
        "        start_time = time_stamp[start_idx]\n",
        "        end_time = start_time + window_size_ns\n",
        "        end_idx = start_idx\n",
        "        while end_idx < len(time_stamp) and time_stamp[end_idx] <= end_time:\n",
        "            end_idx += 1\n",
        "\n",
        "        # Extract window\n",
        "        window_x = x[start_idx:end_idx]\n",
        "        window_y = y[start_idx:end_idx]\n",
        "        window_z = z[start_idx:end_idx]\n",
        "\n",
        "        if window_x:\n",
        "            # Standard deviation\n",
        "            std_x, std_y, std_z = np.std(window_x), np.std(window_y), np.std(window_z)\n",
        "\n",
        "            # Signal magnitude area (SMA)\n",
        "            sma = np.sum(np.abs(window_x) + np.abs(window_y) + np.abs(window_z)) / len(window_x)\n",
        "\n",
        "            # Root-mean-square (RMS)\n",
        "            rms_x = np.sqrt(np.mean(np.square(window_x)))\n",
        "            rms_y = np.sqrt(np.mean(np.square(window_y)))\n",
        "            rms_z = np.sqrt(np.mean(np.square(window_z)))\n",
        "\n",
        "            # Skewness\n",
        "            skew_x = skew(window_x)\n",
        "            skew_y = skew(window_y)\n",
        "            skew_z = skew(window_z)\n",
        "\n",
        "            # Kurtosis\n",
        "            kurt_x = kurtosis(window_x)\n",
        "            kurt_y = kurtosis(window_y)\n",
        "            kurt_z = kurtosis(window_z)\n",
        "\n",
        "            # Append all features to results (excluding dominant frequency)\n",
        "            results.append([\n",
        "                std_x, std_y, std_z, sma,\n",
        "                rms_x, rms_y, rms_z, skew_x, skew_y, skew_z, kurt_x, kurt_y, kurt_z\n",
        "            ])\n",
        "\n",
        "        next_start_time = start_time + stride_ns\n",
        "        while start_idx < len(time_stamp) and time_stamp[start_idx] < next_start_time:\n",
        "            start_idx += 1\n",
        "\n",
        "    return results\n",
        "\n",
        "def process_dataset(dataset_path):\n",
        "    data = []\n",
        "    columns = [\n",
        "        \"activity_name\", \"activity_no\", \"window_no\",\n",
        "        \"acc_std_x\", \"acc_std_y\", \"acc_std_z\", \"acc_sma\",\n",
        "        \"acc_rms_x\", \"acc_rms_y\", \"acc_rms_z\", \"acc_skew_x\", \"acc_skew_y\", \"acc_skew_z\", \"acc_kurt_x\", \"acc_kurt_y\", \"acc_kurt_z\",\n",
        "        \"gyro_std_x\", \"gyro_std_y\", \"gyro_std_z\", \"gyro_sma\",\n",
        "        \"gyro_rms_x\", \"gyro_rms_y\", \"gyro_rms_z\", \"gyro_skew_x\", \"gyro_skew_y\", \"gyro_skew_z\", \"gyro_kurt_x\", \"gyro_kurt_y\", \"gyro_kurt_z\"\n",
        "    ]\n",
        "\n",
        "    total_files = sum(1 for _, _, files in os.walk(dataset_path) for file in files if file.endswith(\".txt\") and 'acc' in file)\n",
        "    print(\"Total files:\", total_files)\n",
        "\n",
        "    processed_files = 0\n",
        "\n",
        "    for root, _, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            if file.endswith(\".txt\") and 'acc' in file:\n",
        "                parsed_filename = file.split('_')\n",
        "                activity_name = parsed_filename[0]\n",
        "                activity_no = parsed_filename[-2] + '.' + parsed_filename[-1].split('.')[0]\n",
        "\n",
        "                # Build associated file names\n",
        "                gyro_filename = f\"{parsed_filename[0]}_gyro_{parsed_filename[2]}_{parsed_filename[3]}\"\n",
        "\n",
        "                # Check if the associated files exist\n",
        "                gyro_path = os.path.join(root, gyro_filename)\n",
        "\n",
        "                acc_results = summarize_file(root, file)\n",
        "                gyro_results = summarize_file(root, gyro_filename) if os.path.exists(gyro_path) else []\n",
        "\n",
        "                # Determine the maximum number of windows\n",
        "                max_windows = max(len(acc_results), len(gyro_results))\n",
        "\n",
        "                # Pad smaller result sets with NaN values\n",
        "                def pad_results(results, max_length):\n",
        "                    padded_results = results + [[np.nan] * len(results[0]) for _ in range(max_length - len(results))]\n",
        "                    return padded_results\n",
        "\n",
        "                if acc_results:\n",
        "                    acc_results = pad_results(acc_results, max_windows)\n",
        "                else:\n",
        "                    acc_results = [[np.nan] * 13 for _ in range(max_windows)]  # 13 features now\n",
        "\n",
        "                if gyro_results:\n",
        "                    gyro_results = pad_results(gyro_results, max_windows)\n",
        "                else:\n",
        "                    gyro_results = [[np.nan] * 13 for _ in range(max_windows)]  # 13 features now\n",
        "\n",
        "                # Combine results into rows\n",
        "                for window_no in range(max_windows):\n",
        "                    row = [activity_name, activity_no, window_no] + acc_results[window_no] + gyro_results[window_no]\n",
        "                    data.append(row)\n",
        "\n",
        "                processed_files += 1\n",
        "                sys.stdout.write(f\"\\rProcessed {processed_files}/{total_files}: {file}\")\n",
        "                sys.stdout.flush()\n",
        "\n",
        "    # Create a DataFrame with the summarized data\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "    return df\n",
        "\n",
        "# Use KaggleHub to download the dataset\n",
        "dataset_path = kagglehub.dataset_download(\"kmknation/mobifall-dataset-v20\")\n",
        "\n",
        "# Verify the path exists\n",
        "path = Path(dataset_path)\n",
        "if path.exists():\n",
        "    print(f\"The path '{path}' exists.\")\n",
        "else:\n",
        "    print(f\"The path '{path}' does not exist.\")\n",
        "\n",
        "# Process the dataset and save the summary\n",
        "df = process_dataset(dataset_path)\n",
        "df.to_csv(\"MobiFall_summary_without_dominant_frequency.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cToz4Ym_YSSQ",
        "outputId": "328e82cd-7216-4e0c-bf52-859384504e3b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The path '/root/.cache/kagglehub/datasets/kmknation/mobifall-dataset-v20/versions/1' exists.\n",
            "Total files: 630\n",
            "Processed 310/630: FOL_acc_11_2.txt"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-638a522aa59c>:65: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  skew_x = skew(window_x)\n",
            "<ipython-input-17-638a522aa59c>:70: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  kurt_x = kurtosis(window_x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 497/630: FKL_acc_4_1.txt"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-638a522aa59c>:67: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  skew_z = skew(window_z)\n",
            "<ipython-input-17-638a522aa59c>:72: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  kurt_z = kurtosis(window_z)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 630/630: FOL_acc_6_3.txt"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ENCODING**"
      ],
      "metadata": {
        "id": "upQy4CP2tMe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Assuming pre_df is your DataFrame\n",
        "def preprocess(pre_df):\n",
        "    # Step 1: Label encode the activity_name\n",
        "    label_encoder = LabelEncoder()\n",
        "    pre_df['activity_name'] = label_encoder.fit_transform(pre_df['activity_name'])\n",
        "\n",
        "    # Step 2: Drop activity_no and window_no\n",
        "    pre_df = pre_df.drop(columns=['activity_no', 'window_no'])\n",
        "\n",
        "    # Step 3: Check and handle NaN or infinite values\n",
        "    pre_df = pre_df.replace([np.inf, -np.inf], np.nan)  # Replace infinite values with NaN\n",
        "    pre_df.dropna(inplace=True)  # Drop rows with NaN\n",
        "\n",
        "    # Step 4: Ensure all features are numeric\n",
        "    pre_df = pre_df.apply(pd.to_numeric, errors='coerce')\n",
        "    pre_df.dropna(inplace=True)  # Drop any rows that couldn't be converted\n",
        "\n",
        "    # Print the mapping of activity names to their encoded values\n",
        "    activity_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
        "    print(\"Activity Name to Encoded Value Mapping:\")\n",
        "    for activity, encoded_value in activity_mapping.items():\n",
        "        print(f\"{activity}: {encoded_value}\")\n",
        "\n",
        "    return pre_df, label_encoder\n",
        "\n",
        "# Example usage\n",
        "# Assuming df is your original DataFrame\n",
        "preprocessed_df, label_encoder = preprocess(df)\n",
        "\n",
        "# Check the results\n",
        "print(preprocessed_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0sL_Wz3gNPo",
        "outputId": "4cd3d9ba-ee3b-4ede-c75f-7df1e0f695ae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activity Name to Encoded Value Mapping:\n",
            "BSC: 0\n",
            "CSI: 1\n",
            "CSO: 2\n",
            "FKL: 3\n",
            "FOL: 4\n",
            "JOG: 5\n",
            "JUM: 6\n",
            "SCH: 7\n",
            "SDL: 8\n",
            "STD: 9\n",
            "STN: 10\n",
            "STU: 11\n",
            "WAL: 12\n",
            "   activity_name  acc_std_x  acc_std_y  acc_std_z    acc_sma  acc_rms_x  \\\n",
            "0              3   4.499141   2.987564   5.127036  16.315239   5.069125   \n",
            "1              3   4.247136   2.789493   4.843027  16.310487   4.961023   \n",
            "2              3   4.021176   2.618092   4.579686  16.306017   4.873326   \n",
            "3              3   3.819695   2.472054   4.315499  16.319557   4.805378   \n",
            "4              3   3.113925   2.306072   3.145883  16.545363   4.811135   \n",
            "\n",
            "   acc_rms_y  acc_rms_z  acc_skew_x  acc_skew_y  ...  gyro_sma  gyro_rms_x  \\\n",
            "0   5.935516   7.167293    0.893955    1.346694  ...  1.299361    0.933942   \n",
            "1   5.763888   7.231539    1.086705    1.528225  ...  1.240739    0.912441   \n",
            "2   5.619333   7.285372    1.269841    1.706692  ...  1.226710    0.912378   \n",
            "3   5.498597   7.337092    1.450987    1.880339  ...  1.188325    0.909819   \n",
            "4   5.187403   7.644553    2.352764    2.447205  ...  1.007137    0.898096   \n",
            "\n",
            "   gyro_rms_y  gyro_rms_z  gyro_skew_x  gyro_skew_y  gyro_skew_z  gyro_kurt_x  \\\n",
            "0    1.259628    0.789276    -2.543371     3.011402    -2.240751     8.181175   \n",
            "1    1.253851    0.789211    -2.726530     3.100743    -2.240488     9.156138   \n",
            "2    1.253262    0.788889    -2.729118     3.110674    -2.252416     9.194946   \n",
            "3    1.252957    0.786974    -2.754663     3.111293    -2.296934     9.228038   \n",
            "4    1.203527    0.748663    -2.914741     3.499454    -2.891364     9.959813   \n",
            "\n",
            "   gyro_kurt_y  gyro_kurt_z  \n",
            "0    34.741714     5.780672  \n",
            "1    35.494542     5.783288  \n",
            "2    35.576346     5.802392  \n",
            "3    35.610970     5.912941  \n",
            "4    42.323290     7.599094  \n",
            "\n",
            "[5 rows x 27 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STANDARDIZE**"
      ],
      "metadata": {
        "id": "4EI064uktWF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def standardize_dataframe(df):\n",
        "  # Initialize dictionary to store mean and std of each column\n",
        "  stats = {}\n",
        "\n",
        "  # Iterate through each column in the DataFrame\n",
        "  for column in df.columns[1:]:\n",
        "          if df[column].dtype in [np.float64, np.int64]:  # Only standardize numerical columns\n",
        "              mean = df[column].mean()\n",
        "              std = df[column].std()\n",
        "\n",
        "              # Store the mean and std\n",
        "              stats[column] = {'mean': mean, 'std': std}\n",
        "\n",
        "              # Apply Z-score standardization\n",
        "              df[column] = (df[column] - mean) / std\n",
        "\n",
        "  return df, stats\n",
        "\n",
        "preprocessed_df,stats=standardize_dataframe(preprocessed_df)\n"
      ],
      "metadata": {
        "id": "3J7V1gSpKdJ6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAVE MEAN/STD**"
      ],
      "metadata": {
        "id": "VOAaWIuQtZ_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the stats dictionary to a DataFrame\n",
        "stats_df = pd.DataFrame.from_dict(stats, orient='index')\n",
        "\n",
        "# Reset index to have a proper column for the keys\n",
        "stats_df.reset_index(inplace=True)\n",
        "stats_df.rename(columns={'index': 'Feature'}, inplace=True)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_file_path = 'stats.csv'\n",
        "stats_df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"Statistics saved to {csv_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DemN8bIXHKM",
        "outputId": "2765f4ee-b6f1-4728-9f1c-74bd28e7a6f1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics saved to stats.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAIN MODEL**"
      ],
      "metadata": {
        "id": "wfGXDw4ktfNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Separate features (X) and target (y)\n",
        "X = preprocessed_df.drop(columns=['activity_name'])\n",
        "y = preprocessed_df['activity_name']\n",
        "\n",
        "# Step 3: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Step 4: Initialize and train the LightGBM model\n",
        "lgb_model = lgb.LGBMClassifier(n_estimators=100, random_state=42)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Make predictions and evaluate the model\n",
        "y_pred = lgb_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "model_file_path = 'lightgbm_model.txt'\n",
        "lgb_model.booster_.save_model(model_file_path)\n"
      ],
      "metadata": {
        "id": "Mc0uYDRZgsmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f77cbcc-e504-48a1-e9ce-97e289bed0eb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012715 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6630\n",
            "[LightGBM] [Info] Number of data points in the train set: 23627, number of used features: 26\n",
            "[LightGBM] [Info] Start training from score -2.802620\n",
            "[LightGBM] [Info] Start training from score -3.607116\n",
            "[LightGBM] [Info] Start training from score -3.613376\n",
            "[LightGBM] [Info] Start training from score -2.796359\n",
            "[LightGBM] [Info] Start training from score -2.810326\n",
            "[LightGBM] [Info] Start training from score -2.693012\n",
            "[LightGBM] [Info] Start training from score -2.693637\n",
            "[LightGBM] [Info] Start training from score -3.605557\n",
            "[LightGBM] [Info] Start training from score -2.808218\n",
            "[LightGBM] [Info] Start training from score -1.489790\n",
            "[LightGBM] [Info] Start training from score -3.092864\n",
            "[LightGBM] [Info] Start training from score -3.101295\n",
            "[LightGBM] [Info] Start training from score -1.489602\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Accuracy: 0.9642796681902828\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       358\n",
            "           1       0.92      0.79      0.85       160\n",
            "           2       0.86      0.87      0.87       159\n",
            "           3       0.92      0.94      0.93       360\n",
            "           4       0.91      0.94      0.92       356\n",
            "           5       1.00      0.99      0.99       400\n",
            "           6       1.00      1.00      1.00       400\n",
            "           7       0.95      0.87      0.91       160\n",
            "           8       0.94      0.95      0.94       356\n",
            "           9       0.98      1.00      0.99      1332\n",
            "          10       0.95      0.91      0.93       268\n",
            "          11       0.96      0.90      0.93       266\n",
            "          12       1.00      1.00      1.00      1332\n",
            "\n",
            "    accuracy                           0.96      5907\n",
            "   macro avg       0.95      0.93      0.94      5907\n",
            "weighted avg       0.96      0.96      0.96      5907\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 343    2    0    1    4    0    0    4    4    0    0    0    0]\n",
            " [   7  126    1    7    7    0    0    3    9    0    0    0    0]\n",
            " [   1    3  139    0    1    0    0    0    0    8    3    4    0]\n",
            " [   4    1    0  339   14    0    0    1    1    0    0    0    0]\n",
            " [   2    1    0   15  333    0    0    0    5    0    0    0    0]\n",
            " [   0    0    0    0    0  397    2    0    0    0    0    0    1]\n",
            " [   0    0    0    0    0    1  399    0    0    0    0    0    0]\n",
            " [   5    2    0    4    6    0    0  139    4    0    0    0    0]\n",
            " [  10    1    0    4    2    0    0    0  339    0    0    0    0]\n",
            " [   0    1    2    0    0    0    0    0    0 1329    0    0    0]\n",
            " [   0    0    8    0    0    0    0    0    0   11  244    4    1]\n",
            " [   0    0   11    0    0    0    0    0    0    6    8  240    1]\n",
            " [   0    0    0    0    0    0    0    0    0    0    1    2 1329]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightgbm.basic.Booster at 0x783d8aa1a110>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONVERT TO ONNX**"
      ],
      "metadata": {
        "id": "_EEfW2kitqMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxmltools\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from onnx import TensorProto\n",
        "from onnx import helper\n",
        "from onnx import numpy_helper\n",
        "from skl2onnx.common.data_types import StringTensorType, FloatTensorType  # Correct import\n",
        "\n",
        "initial_types = [\n",
        "    ('X', FloatTensorType([None, X_train.shape[1]]))  # Features: acc_std_x, acc_std_y, ..., ori_df_z\n",
        "]\n",
        "\n",
        "# Convert the trained LightGBM model to ONNX\n",
        "onnx_model = onnxmltools.convert_lightgbm(lgb_model, initial_types=initial_types)\n",
        "\n",
        "# Save the model as a .onnx file\n",
        "onnxmltools.utils.save_model(onnx_model, 'lightgbm_model.onnx')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j4aFbkNgyqO",
        "outputId": "009f1254-9df6-4aba-b5c4-b9a269e139ed"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:onnxmltools:The maximum opset needed by this model is only 9.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.iloc[0:2,1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "kKrXj3pbxSJj",
        "outputId": "b8f6bd93-2757-47fe-f81c-35c6f501970a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   acc_std_y  acc_std_z   acc_sma  acc_df_x  acc_df_y  acc_df_z  gyro_std_x  \\\n",
              "0   0.487331   2.976688  0.862340  0.211859  0.057242  0.368497    0.614769   \n",
              "1   0.427042   2.947070  0.892204  0.211859  0.057242  0.226294    0.494084   \n",
              "\n",
              "   gyro_std_y  gyro_std_z  gyro_sma  gyro_df_x  gyro_df_y  gyro_df_z  \\\n",
              "0    0.545008    0.050875 -0.006331   0.024636   2.038729  -0.153325   \n",
              "1    0.469881   -0.079226 -0.070860   0.178101  -1.307381  -0.153325   \n",
              "\n",
              "   ori_std_x  ori_std_y  ori_std_z   ori_sma  ori_df_x  ori_df_y  ori_df_z  \n",
              "0   4.391725   2.019205   0.111307 -0.485411  0.009877  0.053748  0.154739  \n",
              "1   4.462546   2.062994   0.177160 -0.410278  0.009877  0.053748  0.154739  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff106b1d-3693-4c49-bac1-cbc55485e638\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc_std_y</th>\n",
              "      <th>acc_std_z</th>\n",
              "      <th>acc_sma</th>\n",
              "      <th>acc_df_x</th>\n",
              "      <th>acc_df_y</th>\n",
              "      <th>acc_df_z</th>\n",
              "      <th>gyro_std_x</th>\n",
              "      <th>gyro_std_y</th>\n",
              "      <th>gyro_std_z</th>\n",
              "      <th>gyro_sma</th>\n",
              "      <th>gyro_df_x</th>\n",
              "      <th>gyro_df_y</th>\n",
              "      <th>gyro_df_z</th>\n",
              "      <th>ori_std_x</th>\n",
              "      <th>ori_std_y</th>\n",
              "      <th>ori_std_z</th>\n",
              "      <th>ori_sma</th>\n",
              "      <th>ori_df_x</th>\n",
              "      <th>ori_df_y</th>\n",
              "      <th>ori_df_z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.487331</td>\n",
              "      <td>2.976688</td>\n",
              "      <td>0.862340</td>\n",
              "      <td>0.211859</td>\n",
              "      <td>0.057242</td>\n",
              "      <td>0.368497</td>\n",
              "      <td>0.614769</td>\n",
              "      <td>0.545008</td>\n",
              "      <td>0.050875</td>\n",
              "      <td>-0.006331</td>\n",
              "      <td>0.024636</td>\n",
              "      <td>2.038729</td>\n",
              "      <td>-0.153325</td>\n",
              "      <td>4.391725</td>\n",
              "      <td>2.019205</td>\n",
              "      <td>0.111307</td>\n",
              "      <td>-0.485411</td>\n",
              "      <td>0.009877</td>\n",
              "      <td>0.053748</td>\n",
              "      <td>0.154739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.427042</td>\n",
              "      <td>2.947070</td>\n",
              "      <td>0.892204</td>\n",
              "      <td>0.211859</td>\n",
              "      <td>0.057242</td>\n",
              "      <td>0.226294</td>\n",
              "      <td>0.494084</td>\n",
              "      <td>0.469881</td>\n",
              "      <td>-0.079226</td>\n",
              "      <td>-0.070860</td>\n",
              "      <td>0.178101</td>\n",
              "      <td>-1.307381</td>\n",
              "      <td>-0.153325</td>\n",
              "      <td>4.462546</td>\n",
              "      <td>2.062994</td>\n",
              "      <td>0.177160</td>\n",
              "      <td>-0.410278</td>\n",
              "      <td>0.009877</td>\n",
              "      <td>0.053748</td>\n",
              "      <td>0.154739</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff106b1d-3693-4c49-bac1-cbc55485e638')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff106b1d-3693-4c49-bac1-cbc55485e638 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff106b1d-3693-4c49-bac1-cbc55485e638');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9f8fd79-1585-411e-8192-385c649464e1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9f8fd79-1585-411e-8192-385c649464e1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9f8fd79-1585-411e-8192-385c649464e1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"acc_std_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04263034414629858,\n        \"min\": 0.42704223061731134,\n        \"max\": 0.48733064147763927,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.42704223061731134,\n          0.48733064147763927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_std_z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020943439544952796,\n        \"min\": 2.947069743327545,\n        \"max\": 2.976688239574758,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.947069743327545,\n          2.976688239574758\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_sma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02111755903542,\n        \"min\": 0.8623397356311617,\n        \"max\": 0.8922044740232672,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8922044740232672,\n          0.8623397356311617\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_df_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.2118586865752744,\n        \"max\": 0.2118586865752744,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.2118586865752744\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_df_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.05724154321817183,\n        \"max\": 0.05724154321817183,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.05724154321817183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_df_z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10055259397165014,\n        \"min\": 0.22629436238759593,\n        \"max\": 0.3684972045140987,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.22629436238759593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gyro_std_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08533694961501027,\n        \"min\": 0.49408383475852197,\n        \"max\": 0.614768506275619,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.49408383475852197\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gyro_std_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05312285854732111,\n        \"min\": 0.46988082759024075,\n        \"max\": 0.5450078946198897,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.46988082759024075\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gyro_std_z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09199553238716879,\n        \"min\": -0.07922624314850929,\n        \"max\": 0.05087508643115813,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          -0.07922624314850929\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gyro_sma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.045628961367347204,\n        \"min\": -0.07086045427499732,\n        \"max\": -0.006331358272296903,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          -0.07086045427499732\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gyro_df_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10851626809877163,\n        \"min\": 0.02463566437587337,\n        \"max\": 0.17810084245927105,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.17810084245927105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gyro_df_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.3660569345852607,\n        \"min\": -1.3073812111007106,\n        \"max\": 2.038728595136676,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          -1.3073812111007106\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gyro_df_z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": -0.15332544156640615,\n        \"max\": -0.15332544156640615,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.15332544156640615\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ori_std_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05007745666291379,\n        \"min\": 4.3917253450253115,\n        \"max\": 4.462545563407155,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4.462545563407155\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ori_std_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03096381486461617,\n        \"min\": 2.0192048941095084,\n        \"max\": 2.0629943410338583,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.0629943410338583\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ori_std_z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04656475911510758,\n        \"min\": 0.11130740288077445,\n        \"max\": 0.1771599167499958,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.1771599167499958\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ori_sma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.053127003731075206,\n        \"min\": -0.48541098262642707,\n        \"max\": -0.4102780534216945,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          -0.4102780534216945\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ori_df_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.009877295977146443,\n        \"max\": 0.009877295977146443,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.009877295977146443\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ori_df_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.053747880980490104,\n        \"max\": 0.053747880980490104,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.053747880980490104\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ori_df_z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.1547387703338033,\n        \"max\": 0.1547387703338033,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.1547387703338033\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEST ONNX MODEL**"
      ],
      "metadata": {
        "id": "zWE2LZBvtuGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load the ONNX model\n",
        "onnx_model_path = 'lightgbm_model.onnx'\n",
        "session = ort.InferenceSession(onnx_model_path)\n",
        "\n",
        "# Prepare a sample input (21 features, replace this with your actual data)\n",
        "# Example of a single sample input with 21 features\n",
        "input_data = np.array([X.iloc[0].values], dtype=np.float32)\n",
        "# Input name should match the one defined in the model (\"X\")\n",
        "input_name = session.get_inputs()[0].name  # 'X'\n",
        "\n",
        "# Run inference\n",
        "output = session.run(None, {input_name: input_data})\n",
        "\n",
        "# Print output: 'label' should be the predicted class\n",
        "print(\"Predicted label:\", output[0],y[0])\n",
        "\n",
        "# If you need probabilities (if they exist)\n",
        "# print(\"Predicted probabilities:\", output[1] if len(output) > 1 else \"No probabilities output\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4arv7LMJi7g1",
        "outputId": "8e466720-c8fd-4ad5-edd9-dca70b75fe77"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: [3] 3\n"
          ]
        }
      ]
    }
  ]
}